{"eval_loss": 2.638969659805298, "eval_accuracy": 0.248359375, "eval_pred_num_tokens": 18.546875, "eval_true_num_tokens": 17.8515625, "eval_token_set_precision": 0.3983511346459998, "eval_token_set_recall": 0.3982150621711936, "eval_token_set_f1": 0.39135654155521016, "eval_token_set_f1_sem": 0.01409830196923846, "eval_n_ngrams_match_1": 5.11, "eval_n_ngrams_match_2": 1.59, "eval_n_ngrams_match_3": 0.755, "eval_num_true_words": 14.825, "eval_num_pred_words": 15.005, "eval_bleu_score": 12.645582506876242, "eval_bleu_score_sem": 1.082896702443237, "eval_exact_match": 0.01, "eval_exact_match_sem": 0.007053278933842965, "eval_ada_emb_cos_sim_mean": 0.8404328227043152, "eval_ada_emb_cos_sim_sem": 0.004306983551732426, "eval_emb_cos_sim": 0.9991239309310913, "eval_emb_cos_sim_sem": 0.00015410789362849657, "eval_emb_top1_equal": 1.0, "eval_emb_top1_equal_sem": 0.0, "eval_perplexity": 13.998772676460947, "eval_runtime": 15.4435, "eval_samples_per_second": 12.95, "eval_steps_per_second": 0.453, "_eval_args": {"alias": "jxm/t5-base__llama-7b-chat__one-million-paired-instructions__60epoch", "dataset": "anthropic_toxic_prompts", "num_samples": 200, "embedder_model_name": "meta-llama/Llama-2-7b-chat-hf"}}