{"eval_loss": 2.5323140621185303, "eval_accuracy": 0.6190476190476191, "eval_pred_num_tokens": 48.5, "eval_true_num_tokens": 14.25, "eval_token_set_precision": 0.4561827061827062, "eval_token_set_recall": 0.23025362318840578, "eval_token_set_f1": 0.28089870478983386, "eval_token_set_f1_sem": 0.0644460883407752, "eval_n_ngrams_match_1": 4.25, "eval_n_ngrams_match_2": 2.0, "eval_n_ngrams_match_3": 1.0, "eval_num_true_words": 10.0, "eval_num_pred_words": 34.25, "eval_bleu_score": 4.836071330018376, "eval_bleu_score_sem": 1.893289270035708, "eval_rouge_score": 0.1881377210066063, "eval_exact_match": 0.0, "eval_exact_match_sem": 0.0, "eval_ada_emb_cos_sim_mean": 0.8004984259605408, "eval_ada_emb_cos_sim_sem": 0.018973486497998238, "eval_emb_cos_sim": 0.9988053441047668, "eval_emb_cos_sim_sem": NaN, "eval_emb_top1_equal": 1.0, "eval_emb_top1_equal_sem": NaN, "eval_perplexity": 12.582589366896402, "eval_runtime": 886.6925, "eval_samples_per_second": 0.005, "eval_steps_per_second": 0.005, "_eval_args": {"alias": "jxm/t5-base__llama-7b__one-million-paired-instructions", "dataset": "anthropic_toxic_prompts", "num_samples": 4, "embedder_model_name": "meta-llama/Llama-2-70b-hf"}}