{"eval_loss": 2.282994270324707, "eval_accuracy": 0.62, "eval_pred_num_tokens": 57.5, "eval_true_num_tokens": 19.75, "eval_token_set_precision": 0.4053030303030303, "eval_token_set_recall": 0.1792468994193132, "eval_token_set_f1": 0.24678305152443086, "eval_token_set_f1_sem": 0.03126565718987232, "eval_n_ngrams_match_1": 6.25, "eval_n_ngrams_match_2": 1.0, "eval_n_ngrams_match_3": 0.25, "eval_num_true_words": 16.0, "eval_num_pred_words": 44.0, "eval_bleu_score": 2.3450325135070713, "eval_bleu_score_sem": 0.47215259753478167, "eval_rouge_score": 0.22399369252250953, "eval_exact_match": 0.0, "eval_exact_match_sem": 0.0, "eval_ada_emb_cos_sim_mean": 0.7163196206092834, "eval_ada_emb_cos_sim_sem": 0.011707312427461147, "eval_emb_cos_sim": 0.9873068928718567, "eval_emb_cos_sim_sem": NaN, "eval_emb_top1_equal": 1.0, "eval_emb_top1_equal_sem": NaN, "eval_perplexity": 9.805998304500243, "eval_runtime": 875.8546, "eval_samples_per_second": 0.005, "eval_steps_per_second": 0.005, "_eval_args": {"alias": "jxm/t5-base__llama-7b-chat__one-million-instructions", "dataset": "python_code_alpaca", "num_samples": 4, "embedder_model_name": "meta-llama/Llama-2-70b-chat-hf"}}