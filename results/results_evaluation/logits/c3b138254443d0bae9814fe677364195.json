{"eval_loss": 1.8229146003723145, "eval_accuracy": 0.713203125, "eval_pred_num_tokens": 36.34375, "eval_true_num_tokens": 23.359375, "eval_token_set_precision": 0.48292376305227486, "eval_token_set_recall": 0.366192065956428, "eval_token_set_f1": 0.40895078049188816, "eval_token_set_f1_sem": 0.00911510981584964, "eval_n_ngrams_match_1": 8.355, "eval_n_ngrams_match_2": 2.96, "eval_n_ngrams_match_3": 1.3, "eval_num_true_words": 18.045, "eval_num_pred_words": 27.76, "eval_bleu_score": 9.603209011439498, "eval_bleu_score_sem": 0.6691753244428936, "eval_exact_match": 0.0, "eval_exact_match_sem": 0.0, "eval_ada_emb_cos_sim_mean": 0.8292825222015381, "eval_ada_emb_cos_sim_sem": 0.004113984176195734, "eval_emb_cos_sim": 0.9966315031051636, "eval_emb_cos_sim_sem": 0.000923273793887347, "eval_emb_top1_equal": 0.75, "eval_emb_top1_equal_sem": 0.25, "eval_perplexity": 6.189873190952192, "eval_runtime": 46.231, "eval_samples_per_second": 4.326, "eval_steps_per_second": 1.082, "_eval_args": {"alias": "jxm/t5-base__llama-7b__one-million-paired-instructions", "dataset": "python_code_alpaca", "num_samples": 200, "embedder_name": "meta-llama/Llama-2-13b-hf"}}