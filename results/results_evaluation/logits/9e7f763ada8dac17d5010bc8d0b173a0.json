{"eval_loss": 3.0924994945526123, "eval_accuracy": 0.61921875, "eval_pred_num_tokens": 52.828125, "eval_true_num_tokens": 17.8515625, "eval_token_set_precision": 0.3268117805685773, "eval_token_set_recall": 0.1798001307308352, "eval_token_set_f1": 0.2191373462256266, "eval_token_set_f1_sem": 0.008615006046289623, "eval_n_ngrams_match_1": 4.675, "eval_n_ngrams_match_2": 0.82, "eval_n_ngrams_match_3": 0.3, "eval_num_true_words": 14.825, "eval_num_pred_words": 39.275, "eval_bleu_score": 2.6578294738447688, "eval_bleu_score_sem": 0.21745346503636304, "eval_exact_match": 0.0, "eval_exact_match_sem": 0.0, "eval_ada_emb_cos_sim_mean": 0.7771666646003723, "eval_ada_emb_cos_sim_sem": 0.0036832252085859762, "eval_emb_cos_sim": 0.9933583736419678, "eval_emb_cos_sim_sem": 0.0020102444104850292, "eval_emb_top1_equal": 0.0, "eval_emb_top1_equal_sem": 0.0, "eval_perplexity": 22.032078270280046, "eval_runtime": 54.7263, "eval_samples_per_second": 3.655, "eval_steps_per_second": 0.914, "_eval_args": {"alias": "jxm/t5-base__llama-7b__one-million-paired-instructions", "dataset": "anthropic_toxic_prompts", "num_samples": 200, "embedder_name": "meta-llama/Llama-2-13b-hf"}}