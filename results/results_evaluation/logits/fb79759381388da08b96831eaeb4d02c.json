{"eval_loss": 2.095498561859131, "eval_accuracy": 0.8484375, "eval_pred_num_tokens": 28.389999389648438, "eval_true_num_tokens": 23.309999465942383, "eval_token_set_precision": 0.4082359988057911, "eval_token_set_recall": 0.3560393367851127, "eval_token_set_f1": 0.37280648868242244, "eval_token_set_f1_sem": 0.014045257372341299, "eval_n_ngrams_match_1": 6.98, "eval_n_ngrams_match_2": 1.83, "eval_n_ngrams_match_3": 0.67, "eval_num_true_words": 18.02, "eval_num_pred_words": 21.87, "eval_bleu_score": 7.684143611326771, "eval_bleu_score_sem": 0.7825047391263593, "eval_rouge_score": 0.33518299092927406, "eval_exact_match": 0.0, "eval_exact_match_sem": 0.0, "eval_ada_emb_cos_sim_mean": 0.0, "eval_ada_emb_cos_sim_sem": 0.0, "eval_emb_cos_sim": 0.9926537275314331, "eval_emb_cos_sim_sem": NaN, "eval_emb_top1_equal": 0.0, "eval_emb_top1_equal_sem": NaN, "eval_perplexity": 8.129493015182598, "eval_runtime": 60.8957, "eval_samples_per_second": 1.642, "eval_steps_per_second": 1.642, "_eval_args": {"alias": "jxm/t5-base__llama-7b-chat__one-million-instructions__emb", "dataset": "python_code_alpaca", "num_samples": 100, "batch_size": 32, "embedder_model_name": "meta-llama/Llama-2-13b-chat-hf"}}