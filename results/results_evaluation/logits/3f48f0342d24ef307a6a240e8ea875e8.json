{"eval_loss": 1.7878856658935547, "eval_accuracy": 0.71, "eval_pred_num_tokens": 28.0, "eval_true_num_tokens": 19.75, "eval_token_set_precision": 0.5606060606060606, "eval_token_set_recall": 0.4492481203007519, "eval_token_set_f1": 0.49485785953177264, "eval_token_set_f1_sem": 0.11174713712902248, "eval_n_ngrams_match_1": 7.75, "eval_n_ngrams_match_2": 4.0, "eval_n_ngrams_match_3": 2.25, "eval_num_true_words": 16.0, "eval_num_pred_words": 20.0, "eval_bleu_score": 18.27769553120545, "eval_bleu_score_sem": 10.606901446956279, "eval_rouge_score": 0.46995820271682337, "eval_exact_match": 0.0, "eval_exact_match_sem": 0.0, "eval_ada_emb_cos_sim_mean": 0.8454540967941284, "eval_ada_emb_cos_sim_sem": 0.021821483969688416, "eval_emb_cos_sim": 0.9990779757499695, "eval_emb_cos_sim_sem": NaN, "eval_emb_top1_equal": 0.0, "eval_emb_top1_equal_sem": NaN, "eval_perplexity": 5.976802140974418, "eval_runtime": 902.547, "eval_samples_per_second": 0.004, "eval_steps_per_second": 0.004, "_eval_args": {"alias": "jxm/t5-base__llama-7b__one-million-paired-instructions", "dataset": "python_code_alpaca", "num_samples": 4, "embedder_model_name": "meta-llama/Llama-2-70b-hf"}}