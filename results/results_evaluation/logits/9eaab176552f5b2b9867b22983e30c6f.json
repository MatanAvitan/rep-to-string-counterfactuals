{"eval_loss": 1.794681429862976, "eval_accuracy": 0.852265625, "eval_pred_num_tokens": 35.671875, "eval_true_num_tokens": 23.359375, "eval_token_set_precision": 0.48177262370897983, "eval_token_set_recall": 0.3625819733494638, "eval_token_set_f1": 0.40633667167443216, "eval_token_set_f1_sem": 0.008790504883837076, "eval_n_ngrams_match_1": 8.365, "eval_n_ngrams_match_2": 2.92, "eval_n_ngrams_match_3": 1.25, "eval_num_true_words": 18.045, "eval_num_pred_words": 27.53, "eval_bleu_score": 9.346479434180749, "eval_bleu_score_sem": 0.6247482528255628, "eval_exact_match": 0.0, "eval_exact_match_sem": 0.0, "eval_ada_emb_cos_sim_mean": 0.8307574987411499, "eval_ada_emb_cos_sim_sem": 0.0039744962834530944, "eval_emb_cos_sim": 0.9995222091674805, "eval_emb_cos_sim_sem": NaN, "eval_emb_top1_equal": 1.0, "eval_emb_top1_equal_sem": NaN, "eval_perplexity": 6.01755740233689, "eval_runtime": 105.4036, "eval_samples_per_second": 1.897, "eval_steps_per_second": 1.897, "_eval_args": {"alias": "jxm/t5-base__llama-7b__one-million-paired-instructions", "dataset": "python_code_alpaca", "num_samples": 200, "embedder_model_name": "meta-llama/Llama-2-13b-hf"}}