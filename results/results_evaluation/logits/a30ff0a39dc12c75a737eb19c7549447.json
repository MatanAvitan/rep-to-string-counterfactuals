{"eval_pred_num_tokens": 20.921875, "eval_true_num_tokens": 23.3359375, "eval_token_set_precision": 0.19570490286195916, "eval_token_set_recall": 0.21876770878140023, "eval_token_set_f1": 0.19211484943369406, "eval_token_set_f1_sem": 0.008199367094379345, "eval_n_ngrams_match_1": 3.105, "eval_n_ngrams_match_2": 0.345, "eval_n_ngrams_match_3": 0.1, "eval_num_true_words": 18.03, "eval_num_pred_words": 16.155, "eval_bleu_score": 3.2558466472667407, "eval_bleu_score_sem": 0.2731008128795806, "eval_exact_match": 0.0, "eval_exact_match_sem": 0.0, "eval_ada_emb_cos_sim_mean": 0.72977614402771, "eval_ada_emb_cos_sim_sem": 0.004847729988887425, "eval_emb_cos_sim": 0.9999958872795105, "eval_emb_cos_sim_sem": 1.234909859704203e-06, "eval_emb_top1_equal": 1.0, "eval_emb_top1_equal_sem": 0.0, "eval_runtime": 821.7586, "eval_samples_per_second": 0.243, "eval_steps_per_second": 0.061, "_eval_args": {"alias": "fewshot", "prompt": "00_output_simple", "max_seq_length": 64, "num_samples": 200, "embedder_model_name": "meta-llama/Llama-2-13b-hf", "dataset": "python_code_alpaca", "gpt_version": "gpt-3.5-turbo-0613", "take_first_line": false}}