{"eval_loss": 0.9976537823677063, "eval_accuracy": 0.45765625, "eval_pred_num_tokens": 22.809999465942383, "eval_true_num_tokens": 23.309999465942383, "eval_token_set_precision": 0.7550746343673724, "eval_token_set_recall": 0.7774290593572828, "eval_token_set_f1": 0.7630071372139545, "eval_token_set_f1_sem": 0.01856316662298559, "eval_n_ngrams_match_1": 12.77, "eval_n_ngrams_match_2": 8.41, "eval_n_ngrams_match_3": 5.93, "eval_num_true_words": 18.02, "eval_num_pred_words": 17.76, "eval_bleu_score": 46.750276738612556, "eval_bleu_score_sem": 2.8273599327237817, "eval_rouge_score": 0.7462778984087107, "eval_exact_match": 0.09, "eval_exact_match_sem": 0.028762349126466143, "eval_ada_emb_cos_sim_mean": 0.0, "eval_ada_emb_cos_sim_sem": 0.0, "eval_emb_cos_sim": 0.9984606504440308, "eval_emb_cos_sim_sem": 0.00024769947766091325, "eval_emb_top1_equal": 0.375, "eval_emb_top1_equal_sem": 0.08695104001533173, "eval_perplexity": 2.7119116235692795, "eval_runtime": 14.6848, "eval_samples_per_second": 6.81, "eval_steps_per_second": 0.272, "_eval_args": {"alias": "jxm/t5-base__llama-7b__one-million-instructions__emb", "dataset": "python_code_alpaca", "num_samples": 100, "batch_size": 32, "embedder_model_name": "meta-llama/Llama-2-7b-hf"}}