{"eval_loss": 2.6857168674468994, "eval_accuracy": 0.2509375, "eval_pred_num_tokens": 17.8984375, "eval_true_num_tokens": 17.8515625, "eval_token_set_precision": 0.40774158599704713, "eval_token_set_recall": 0.4175333269031751, "eval_token_set_f1": 0.4062014030810034, "eval_token_set_f1_sem": 0.01563852535835527, "eval_n_ngrams_match_1": 5.07, "eval_n_ngrams_match_2": 1.725, "eval_n_ngrams_match_3": 0.87, "eval_num_true_words": 14.825, "eval_num_pred_words": 14.365, "eval_bleu_score": 14.648025373692779, "eval_bleu_score_sem": 1.3174307580766176, "eval_rouge_score": 0.38226652170952274, "eval_exact_match": 0.02, "eval_exact_match_sem": 0.0099243368701167, "eval_ada_emb_cos_sim_mean": 0.8521302938461304, "eval_ada_emb_cos_sim_sem": 0.0041046755178664966, "eval_emb_cos_sim": 0.9994102716445923, "eval_emb_cos_sim_sem": 0.00014827403304792054, "eval_emb_top1_equal": 1.0, "eval_emb_top1_equal_sem": 0.0, "eval_perplexity": 14.668713134979527, "eval_runtime": 16.8111, "eval_samples_per_second": 11.897, "eval_steps_per_second": 0.416, "_eval_args": {"alias": "jxm/t5-base__llama-7b-chat__one-million-instructions", "dataset": "anthropic_toxic_prompts", "num_samples": 200, "embedder_model_name": "meta-llama/Llama-2-7b-chat-hf"}}