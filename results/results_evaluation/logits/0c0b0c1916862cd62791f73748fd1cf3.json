{"eval_loss": 1.3575539588928223, "eval_accuracy": 0.8784375, "eval_pred_num_tokens": 31.689998626708984, "eval_true_num_tokens": 29.51999855041504, "eval_token_set_precision": 0.5402621951248403, "eval_token_set_recall": 0.5372851698113363, "eval_token_set_f1": 0.5301146120328174, "eval_token_set_f1_sem": 0.019520349541060886, "eval_n_ngrams_match_1": 11.57, "eval_n_ngrams_match_2": 6.33, "eval_n_ngrams_match_3": 4.31, "eval_num_true_words": 23.13, "eval_num_pred_words": 24.28, "eval_bleu_score": 24.461435946468264, "eval_bleu_score_sem": 2.137634967001864, "eval_rouge_score": 0.4752388298726873, "eval_exact_match": 0.02, "eval_exact_match_sem": 0.014070529413628966, "eval_ada_emb_cos_sim_mean": 0.0, "eval_ada_emb_cos_sim_sem": 0.0, "eval_emb_cos_sim": 0.9993857145309448, "eval_emb_cos_sim_sem": NaN, "eval_emb_top1_equal": 0.0, "eval_emb_top1_equal_sem": NaN, "eval_perplexity": 3.8866746990102694, "eval_runtime": 216.2784, "eval_samples_per_second": 0.462, "eval_steps_per_second": 0.462, "_eval_args": {"alias": "jxm/t5-base__llama-7b__one-million-instructions__emb", "dataset": "one_million_instructions", "num_samples": 100, "batch_size": 32, "embedder_model_name": "meta-llama/Llama-2-70b-hf"}}