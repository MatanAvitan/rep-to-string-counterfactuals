{"eval_loss": 0.8638306260108948, "eval_accuracy": 0.42265625, "eval_pred_num_tokens": 29.03999900817871, "eval_true_num_tokens": 29.51999855041504, "eval_token_set_precision": 0.7552364143138578, "eval_token_set_recall": 0.7745795664145939, "eval_token_set_f1": 0.7620739629980199, "eval_token_set_f1_sem": 0.02220187093431241, "eval_n_ngrams_match_1": 15.85, "eval_n_ngrams_match_2": 12.14, "eval_n_ngrams_match_3": 10.08, "eval_num_true_words": 23.13, "eval_num_pred_words": 22.65, "eval_bleu_score": 59.44240225379036, "eval_bleu_score_sem": 3.1937588525046285, "eval_rouge_score": 0.726913639768304, "eval_exact_match": 0.26, "eval_exact_match_sem": 0.0440844002276808, "eval_ada_emb_cos_sim_mean": 0.0, "eval_ada_emb_cos_sim_sem": 0.0, "eval_emb_cos_sim": 0.9970555305480957, "eval_emb_cos_sim_sem": 0.000634370738501753, "eval_emb_top1_equal": 0.375, "eval_emb_top1_equal_sem": 0.08695104001533173, "eval_perplexity": 2.372230438837281, "eval_runtime": 14.668, "eval_samples_per_second": 6.818, "eval_steps_per_second": 0.273, "_eval_args": {"alias": "jxm/t5-base__llama-7b-chat__one-million-instructions__emb", "dataset": "one_million_instructions", "num_samples": 100, "batch_size": 32, "embedder_model_name": "meta-llama/Llama-2-7b-chat-hf"}}