{"eval_loss": 2.6006510257720947, "eval_accuracy": 0.240390625, "eval_pred_num_tokens": 39.453125, "eval_true_num_tokens": 17.8515625, "eval_token_set_precision": 0.4519639785199379, "eval_token_set_recall": 0.30743841318762744, "eval_token_set_f1": 0.3487704837459838, "eval_token_set_f1_sem": 0.012465881547764224, "eval_n_ngrams_match_1": 6.005, "eval_n_ngrams_match_2": 1.995, "eval_n_ngrams_match_3": 0.985, "eval_num_true_words": 14.825, "eval_num_pred_words": 29.77, "eval_bleu_score": 7.96702741702751, "eval_bleu_score_sem": 0.7760455577017241, "eval_exact_match": 0.005, "eval_exact_match_sem": 0.005000000000000001, "eval_ada_emb_cos_sim_mean": 0.8306765556335449, "eval_ada_emb_cos_sim_sem": 0.0044579743731049, "eval_emb_cos_sim": 0.996514081954956, "eval_emb_cos_sim_sem": 0.0005984104628940074, "eval_emb_top1_equal": 0.5, "eval_emb_top1_equal_sem": 0.08980264837037424, "eval_perplexity": 13.472506129269194, "eval_runtime": 16.8457, "eval_samples_per_second": 11.872, "eval_steps_per_second": 0.416, "_eval_args": {"alias": "jxm/t5-base__llama-7b__one-million-paired-instructions", "dataset": "anthropic_toxic_prompts", "num_samples": 200, "embedder_name": "meta-llama/Llama-2-7b-hf"}}