{"eval_loss": 2.829257011413574, "eval_accuracy": 0.87484375, "eval_pred_num_tokens": 16.219999313354492, "eval_true_num_tokens": 17.479999542236328, "eval_token_set_precision": 0.4518718939799449, "eval_token_set_recall": 0.45891514626670904, "eval_token_set_f1": 0.4475558864901537, "eval_token_set_f1_sem": 0.021749246001869883, "eval_n_ngrams_match_1": 5.68, "eval_n_ngrams_match_2": 1.94, "eval_n_ngrams_match_3": 0.92, "eval_num_true_words": 14.4, "eval_num_pred_words": 13.3, "eval_bleu_score": 15.153126255448027, "eval_bleu_score_sem": 1.8019422636190494, "eval_rouge_score": 0.4154417753397294, "eval_exact_match": 0.02, "eval_exact_match_sem": 0.014070529413628966, "eval_ada_emb_cos_sim_mean": 0.0, "eval_ada_emb_cos_sim_sem": 0.0, "eval_emb_cos_sim": 0.9927423596382141, "eval_emb_cos_sim_sem": NaN, "eval_emb_top1_equal": 0.0, "eval_emb_top1_equal_sem": NaN, "eval_perplexity": 16.93287521661715, "eval_runtime": 203.6208, "eval_samples_per_second": 0.491, "eval_steps_per_second": 0.491, "_eval_args": {"alias": "jxm/t5-base__llama-7b__one-million-instructions__emb", "dataset": "anthropic_toxic_prompts", "num_samples": 100, "batch_size": 32, "embedder_model_name": "meta-llama/Llama-2-70b-hf"}}