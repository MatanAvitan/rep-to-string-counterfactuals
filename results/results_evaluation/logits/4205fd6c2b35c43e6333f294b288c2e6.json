{"eval_loss": 2.3957061767578125, "eval_accuracy": 0.1915625, "eval_pred_num_tokens": 17.3799991607666, "eval_true_num_tokens": 17.479999542236328, "eval_token_set_precision": 0.5670833326164902, "eval_token_set_recall": 0.5661547317911879, "eval_token_set_f1": 0.5619487050137544, "eval_token_set_f1_sem": 0.022987495192775684, "eval_n_ngrams_match_1": 7.12, "eval_n_ngrams_match_2": 3.05, "eval_n_ngrams_match_3": 1.6, "eval_num_true_words": 14.4, "eval_num_pred_words": 14.05, "eval_bleu_score": 23.958827950565784, "eval_bleu_score_sem": 2.24051868653825, "eval_rouge_score": 0.5366816123928794, "eval_exact_match": 0.05, "eval_exact_match_sem": 0.021904291355759033, "eval_ada_emb_cos_sim_mean": 0.0, "eval_ada_emb_cos_sim_sem": 0.0, "eval_emb_cos_sim": 0.9968125820159912, "eval_emb_cos_sim_sem": 0.00037798285484313965, "eval_emb_top1_equal": 0.328125, "eval_emb_top1_equal_sem": 0.05915529280900955, "eval_perplexity": 10.975946281109987, "eval_runtime": 13.4005, "eval_samples_per_second": 7.462, "eval_steps_per_second": 0.149, "_eval_args": {"alias": "jxm/t5-base__llama-7b__one-million-instructions__emb", "dataset": "anthropic_toxic_prompts", "num_samples": 100, "batch_size": 64, "embedder_model_name": "meta-llama/Llama-2-7b-hf"}}