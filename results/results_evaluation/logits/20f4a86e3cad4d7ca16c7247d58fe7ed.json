{"eval_loss": 3.01727294921875, "eval_accuracy": 0.85640625, "eval_pred_num_tokens": 20.829999923706055, "eval_true_num_tokens": 17.479999542236328, "eval_token_set_precision": 0.35050488198425284, "eval_token_set_recall": 0.3160134672849559, "eval_token_set_f1": 0.32517439854334035, "eval_token_set_f1_sem": 0.01976006649030953, "eval_n_ngrams_match_1": 4.64, "eval_n_ngrams_match_2": 1.25, "eval_n_ngrams_match_3": 0.48, "eval_num_true_words": 14.4, "eval_num_pred_words": 16.54, "eval_bleu_score": 9.287528606002056, "eval_bleu_score_sem": 1.2885300730301634, "eval_rouge_score": 0.2890334218944339, "eval_exact_match": 0.01, "eval_exact_match_sem": 0.009999999999999998, "eval_ada_emb_cos_sim_mean": 0.0, "eval_ada_emb_cos_sim_sem": 0.0, "eval_emb_cos_sim": 0.9981914162635803, "eval_emb_cos_sim_sem": NaN, "eval_emb_top1_equal": 1.0, "eval_emb_top1_equal_sem": NaN, "eval_perplexity": 20.435487016861597, "eval_runtime": 52.215, "eval_samples_per_second": 1.915, "eval_steps_per_second": 1.915, "_eval_args": {"alias": "jxm/t5-base__llama-7b-chat__one-million-instructions__emb", "dataset": "anthropic_toxic_prompts", "num_samples": 100, "batch_size": 32, "embedder_model_name": "meta-llama/Llama-2-13b-chat-hf"}}